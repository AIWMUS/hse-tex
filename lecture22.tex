\section{Лекция 22.02.2017}

$V$ -- векторное пространство над $\RR$, $dimV = n < \infty$

$Q: V \rightarrow \RR$ -- квадратичная форма

Фиксированный базис $e = (e_1, \dots, e_n)$ в $V$

$B = B(Q, e)$

$B_k$ -- левый верхний $k \times k$-блок в $B$

$\delta_k = det B_k$ -- $k$-ый угловой минор матрицы $B$

\vspace{\baselineskip}
\textbf{Теорема (критерий Сильвестра положительной определенности).} $Q > 0 \Leftrightarrow \delta_k > 0 \ \forall \ k = 1, \dots, n$

\vspace{\baselineskip}
\textbf{\textit{Доказательство.}} $\rhd \ (\Leftarrow)$ Пусть $\delta_k > 0 \ \forall \ k = 1, \dots, n$

Метод Якоби $\Rightarrow \exists$ базис, в котором $Q$ записывается в виде $\delta_1 x_1^2 + \frac{\delta_2}{\delta_1} x_2^2 + \dots + \frac{\delta_n}{\delta_{n-1}} x_n^2 \Rightarrow Q > 0$.

$(\Rightarrow) Q > 0 \Rightarrow \exists C \in M_n(\RR), detC \neq 0$, такая что $C^T B C = E \Rightarrow det(C^T) det B det C = 1 \Rightarrow \delta_n = det B = \frac{1}{(det C)^2} > 0 \Rightarrow \delta_n > 0 \ \forall k = 1, \dots, n-1$ ограничение квадратичной формы $Q$ на подпространство $<e_1, \dots, e_k>$ тоже положительно определено, матрица этого ограничения в базисе $(e_1, \dots, e_k)$ есть $B_k$.

Тогда по предыдущему рассуждению получаем $\delta_k = det B_k > 0 \ \lhd$

\vspace{\baselineskip}
\textbf{Следствие.} $Q < 0 \Leftrightarrow \begin{cases} \delta_k < 0 \ при \ k \ mod \ 2 = 1 \\
\delta_k > 0 \ при \ k \ mod \ 2 = 0 \end{cases}$

\vspace{\baselineskip}
\textbf{\textit{Доказательство.}} $\rhd \ Q < 0 \Leftrightarrow - Q > 0$ дальше критерий Сильвестра $\lhd$  

\vspace{\baselineskip}
\subsection{Евклидовы пространства}

\textbf{Определение.} \textit{Евклидово пространство} -- это векторное пространство над $\RR$, на котором задана симметричная положительно определенная ($\Leftrightarrow (x, x) > 0$) билинейная форма $(\cdot, \cdot)$.

Билинейная форма $( \cdot, \cdot)$ называется \textit{скалярным произведением}.

\vspace{\baselineskip}
Примеры.

1) $R^n$ со скалярным произведением

$(x, y) = x_1 y_1 + \dots + x_n y_n$

$(x, x) = x_1^2 + \dots + x_n^2 > 0$

2) $Mat_{m \times n} (\RR)$ со скалярным произведением

$(A, B) := tr (A^T B)$

$(A, A) = tr (A^T A) = \sum\limits_{i = 1}^m \sum\limits_{j = 1}^n {a_{ij}}^2 > 0$

3) $C[0, 1]$ со скалярным произведением 

$(f, g) = \int_0^1 f(t) g(t) dt$

$(f, f) = \int_0^1 {f(t)^2} dt > 0$

\vspace{\baselineskip}
Пусть $E$ -- евклидово пространство

\vspace{\baselineskip}
\textbf{Определение.} \textit{Длина вектора} $v \in E$ это число $|v| = \sqrt[]{(v, v)}$. Заметим, что $|v| \geq 0$, причем $|v| = 0 \Leftrightarrow v = 0$.

\vspace{\baselineskip}
\textbf{Замечание.} В примере 2) длина матрицы $A$ называется ее \textit{нормой Фробениуса}.

\vspace{\baselineskip}
\textbf{Предложение (неравенство Коши-Буняковского).} $\forall \ x, y \in E$ верно $|(x, y)| \leq |x| |y|$, причем равенство $\Leftrightarrow x, y$ пропорциональны.

\vspace{\baselineskip}
\textbf{\textit{Доказательство.}} $\rhd$ 1) Пусть $x, y$ пропорциональны. Без ограничения общности: $y = \lambda x$. Тогда $|(x, \lambda x)| = |\lambda(x, x)| = |\lambda||(x, x)| = |\lambda||x|^2 = |x||y|$

2) $x, y$ не пропорциональны $\Rightarrow x, y$ образуют базис в $<x, y>$. Тогда, рассмотрев $(\cdot, \cdot)|_{<x, y>}$ и применив критерий Сильвестра, получим $\begin{vmatrix} (x,x) & (x,y) \\ (y,x) & (y,y) \end{vmatrix} > 0 \Rightarrow (x,x)(y,y) - (x,y)^2 > 0 \Rightarrow |(x, y)|^2 < |x|^2 |y|^2 \ \lhd$

\vspace{\baselineskip}
\textbf{Следствие.} $\forall \ x, y \in E, xy \neq 0$, имеем $-1 \leq \frac{(x,y)}{|x||y|} \leq 1$ 

\vspace{\baselineskip}
\textbf{Определение.} \textit{Угол между ненулевыми векторами} $x, y \in E$ -- это такой $\alpha \in [0; \pi]$, что $\cos \alpha = \frac{(x,y)}{|x||y|}$.

\vspace{\baselineskip}
$v_1, \dots, v_k \in E$

\textbf{Определение.} \textit{Матрица Грама} системы векторов $(v_1, \dots, v_k)$ -- это матрица $G(v_1, \dots, v_k) = \begin{pmatrix} (v_1, v_1) & (v_1, v_2) & \dots & (v_1, v_k) \\
(v_2, v_1) & (v_2, v_2) & \dots & (v_2, v_k) \\
\vdots & \vdots & \vdots & \vdots \\
(v_k, v_1) & (v_k, v_2) & \dots & (v_k, v_k) \end{pmatrix}$.

\vspace{\baselineskip}
\textbf{Предложение.} $detG(v_1, \dots, v_k) \geq 0$, причем $detG(v_1, \dots, v_k) = 0 \Leftrightarrow v_1, \dots, v_k$ линейно зависимы.

\vspace{\baselineskip}
\textbf{\textit{Доказательство.}} $\rhd$ 1) $v_1, \dots, v_k$ линейно независимые. Тогда $v_1, \dots, v_k$ -- базис в $<v_1, \dots, v_k>$. Рассмотрим $(\cdot, \cdot)|_{<v_1, \dots, v_k>}$ и, применяя критерий Сильвестра, получаем $detG(v_1, \dots, v_k) > 0$.

2) $v_1, \dots, v_k$ линейно зависимы. Пусть $\alpha_1 v_1 + \dots + \alpha_k v_k = 0$, где $\alpha_1, \dots, \alpha_k \in \RR^k \setminus \{0\}$. $\forall \ j = 1, \dots, k$ имеем $(\alpha_1 v_1 + \dots + \alpha_k v_k, v_j) = 0 \Rightarrow \alpha_1 (v_1, v_j) + \dots + \alpha_k (v_k, v_j) = 0 \Rightarrow \alpha_1 G_{(1)} + \dots + \alpha_k G_{(k)} = 0$, где $G = G(v_1, \dots, v_k) \Rightarrow detG = 0 \ \lhd$.

\vspace{\baselineskip}
$E$ -- евклидово пространство

\textbf{Определение.} Векторы $x, y \in E$ называются \textit{ортогональными}, если $(x, y) = 0$.

\vspace{\baselineskip}
$S \subseteq E$ -- подмножество

\textbf{Определение.} \textit{Ортогональным дополнением множества} $S$ называется $S^{\bot} = \{ \ x \in E \ | \ (x, y) = 0 \ \forall \ y \in S \}$.

\vspace{\baselineskip}
\textbf{\textit{Упражнение.}} 1) $S^{\bot}$ -- подпространство в $E$

2) $S^{\bot} = <S>^{\bot}$

\vspace{\baselineskip}
Пусть $S$ -- подпространство в $E$, $dimE = n$

\textbf{Предложение.} a) $dimS^{\bot} = n - dimS$

б) $E = S \oplus S^{\bot}$

в) $(S^{\bot})^{\bot} = S$

\vspace{\baselineskip}
\textbf{\textit{Доказательство.}} $\rhd$ (а) Пусть $<e_1, \dots, e_k>$  -- базис в $S$. Дополним его до базиса $(e_1, \dots, e_n)$ всего пространства $E$.

$x \in E \Rightarrow x = x_1 e_1 + \dots + x_n e_n$

$x \in S^{\bot} \Leftrightarrow (x, e_i) = 0 \ \forall i = 1, \dots, k \Leftrightarrow (x_1, \dots, x_n)$ -- решение ОСЛУ

$\begin{cases}
(e_1, e_1) x_1 + \dots + (e_n, e_1) x_n = 0 \\
(e_1, e_2) x_1 + \dots + (e_n, e_2) x_n = 0 \\
\vdots \\
(e_1, e_k) x_1 + \dots + (e_n, e_k) x_n = 0
\end{cases}$

Матрица этой системы есть $G = ((e_i, e_j))_{i=1, \dots, k; j = 1, \dots, n}$

У этой матрицы левый $k \times k$ блок есть $G(v_1, \dots, v_k) \Rightarrow det G(v_1, \dots, v_k) > 0 \Rightarrow rkG = k \Rightarrow dim S^{\bot} = n - k = n - dimS$.

(б) $dimS + dim S^{\bot} = n = dimE$

$v \in S \cap S^{\bot} \Rightarrow (v, v) = 0 \Rightarrow v = 0 \Rightarrow S \cap S^{\bot} = \{0\} \Rightarrow E = S \oplus S^{\bot}$

(в) $S \subseteq (S^{\bot})^{\bot}$ из определения

Но $dim(S^{\bot})^{\bot} = n - dim S^{\bot} = dim S \Rightarrow S = (S^{\bot})^{\bot} \ \lhd$.

\vspace{\baselineskip}
Из (б) следует, что $\forall v \in E \ \exists! x \in S, y \in S^{\bot}$, такие что $v = x + y$.

\vspace{\baselineskip}
\textbf{Определение.} $x$ называется \textit{ортогональной проекцией} вектора $v$ на подпростанство $S$. Обозначение: $x = pr_S v$

$y$ называется \textit{ортогональной составляющей} вектора $v$ относительно $S$. Обозначение: $x = ort_S v$

$v = pr_S v + ort_S v$

\vspace{\baselineskip}
Пусть $E = \RR^n$, со стандартным скалярным произведением

$U \subseteq \RR^n$ -- подпространство

$(a_1, \dots, a_k)$ -- базис $U$

Образуем матрицу $A = (a_1, \dots, a_k) \in Mat_{n \times k} (\RR)$

\vspace{\baselineskip}
\textbf{Теорема.} $v \in E \Leftrightarrow pr_U v = A (A^T A)^{-1} A^T v$

\vspace{\baselineskip}
\textbf{\textit{Доказательство.}} $\rhd$ Корректность: $A^T A = G(a_1, \dots, a_k)$

$(a_1, \dots, a_k)$ линейно независимые $\Rightarrow det A^T A \neq 0 \Rightarrow \exists (A^T A)$

Пусть $v \in E, v = x + y$, где $x = pr_U v, y = ort_U v$

$x \in U \Rightarrow x \in <a_1, \dots, a_k> \Rightarrow x  = A \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_k \end{pmatrix}$, где $\alpha_i \in \RR$

$y \in U^{\bot} \Rightarrow A^T y = 0$

$A (A^T A)^{-1} A^T v = A (A^T A)^{-1} A^T (x + y) = A (A^T A)^{-1} A^T x + A (A^T A)^{-1} A^T y = A (A^T A)^{-1} A^T A \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_k \end{pmatrix} = A \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_k \end{pmatrix} = pr_U v \ \lhd$

